#!/usr/bin/env python3
"""
ì£¼ê°„ F1 í†µê³„ ìŠ¤í¬ë˜í•‘ ìŠ¤ì¼€ì¤„ëŸ¬
ë§¤ì£¼ ì›”ìš”ì¼ ì‹¤í–‰ë˜ì–´ ë“œë¼ì´ë²„ ë° íŒ€ í†µê³„ë¥¼ ì—…ë°ì´íŠ¸
"""

import os
import sys
import subprocess
import logging
from datetime import datetime, timedelta
from pathlib import Path

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/Users/hangyu/Desktop/Overtake/backend/weekly_scraper.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

def run_weekly_scraper():
    """ì£¼ê°„ ìŠ¤í¬ë˜í•‘ ì‹¤í–‰"""
    try:
        # í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ì˜ ë””ë ‰í† ë¦¬ë¡œ ì´ë™
        script_dir = Path(__file__).parent
        os.chdir(script_dir)
        
        logger.info("=== Weekly F1 Statistics Scraping Started ===")
        logger.info(f"Working directory: {os.getcwd()}")
        logger.info(f"Execution time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # ê°€ìƒí™˜ê²½ Python ê²½ë¡œ
        venv_python = script_dir / "venv" / "bin" / "python3"
        
        # ìŠ¤í¬ë˜í•‘ ìŠ¤í¬ë¦½íŠ¸ë“¤
        driver_scraper = script_dir / "bulk_driver_scraper.py"
        team_scraper = script_dir / "team_season_scraper.py"
        
        # ê°€ìƒí™˜ê²½ Python ê²½ë¡œ í™•ì¸
        if not venv_python.exists():
            logger.error(f"Virtual environment Python not found at: {venv_python}")
            return False
        
        # ë“œë¼ì´ë²„ ìŠ¤í¬ë˜í•‘ ì‹¤í–‰
        logger.info("1. Starting driver statistics scraping...")
        if not driver_scraper.exists():
            logger.error(f"Driver scraper script not found at: {driver_scraper}")
            return False
        
        driver_result = subprocess.run(
            [str(venv_python), str(driver_scraper)],
            capture_output=True,
            text=True,
            timeout=3600  # 1ì‹œê°„ íƒ€ì„ì•„ì›ƒ
        )
        
        # íŒ€ ìŠ¤í¬ë˜í•‘ ì‹¤í–‰
        logger.info("2. Starting team statistics scraping...")
        if not team_scraper.exists():
            logger.error(f"Team scraper script not found at: {team_scraper}")
            return False
        
        team_result = subprocess.run(
            [str(venv_python), str(team_scraper)],
            capture_output=True,
            text=True,
            timeout=1800  # 30ë¶„ íƒ€ì„ì•„ì›ƒ
        )
        
        # ê²°ê³¼ í™•ì¸
        driver_success = driver_result.returncode == 0
        team_success = team_result.returncode == 0
        
        if driver_success:
            logger.info("âœ… Driver scraping completed successfully!")
            logger.info(f"Driver output: {driver_result.stdout}")
        else:
            logger.error(f"âŒ Driver scraping failed with return code: {driver_result.returncode}")
            logger.error(f"Driver error: {driver_result.stderr}")
        
        if team_success:
            logger.info("âœ… Team scraping completed successfully!")
            logger.info(f"Team output: {team_result.stdout}")
        else:
            logger.error(f"âŒ Team scraping failed with return code: {team_result.returncode}")
            logger.error(f"Team error: {team_result.stderr}")
        
        if driver_success and team_success:
            # JSON íŒŒì¼ë“¤ ìƒì„± í™•ì¸ ë° ë°±ì—…
            files_to_check = [
                ("driver_career_stats.json", "driver_career_stats_backup"),
                ("team_2025_season_stats.json", "team_2025_season_backup")
            ]
            
            success_count = 0
            import shutil
            
            for json_file, backup_prefix in files_to_check:
                json_path = script_dir / json_file
                
                if json_path.exists():
                    file_size = json_path.stat().st_size
                    logger.info(f"ğŸ“„ {json_file} updated (size: {file_size} bytes)")
                    
                    # íŒŒì¼ ë°±ì—… ìƒì„±
                    backup_name = f"{backup_prefix}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                    backup_path = script_dir / "backups" / backup_name
                    
                    # ë°±ì—… ë””ë ‰í† ë¦¬ ìƒì„±
                    backup_path.parent.mkdir(exist_ok=True)
                    
                    # ë°±ì—… íŒŒì¼ ë³µì‚¬
                    shutil.copy2(json_path, backup_path)
                    logger.info(f"ğŸ“ Backup created: {backup_path}")
                    
                    success_count += 1
                else:
                    logger.error(f"âŒ {json_file} was not created")
            
            # ì˜¤ë˜ëœ ë°±ì—… íŒŒì¼ ì •ë¦¬ (30ì¼ ì´ìƒ)
            cleanup_old_backups(script_dir / "backups", days=30)
            
            return success_count == 2  # ë‘ íŒŒì¼ ëª¨ë‘ ì„±ê³µí•´ì•¼ True
        else:
            logger.error("âŒ One or both scraping tasks failed")
            return False
            
    except subprocess.TimeoutExpired:
        logger.error("âŒ Scraping timed out after 1 hour")
        return False
    except Exception as e:
        logger.error(f"âŒ Unexpected error: {e}")
        return False

def cleanup_old_backups(backup_dir, days=30):
    """ì˜¤ë˜ëœ ë°±ì—… íŒŒì¼ ì •ë¦¬"""
    try:
        cutoff_date = datetime.now() - timedelta(days=days)
        
        # ë“œë¼ì´ë²„ ë°±ì—… íŒŒì¼ ì •ë¦¬
        for backup_file in backup_dir.glob("driver_career_stats_backup_*.json"):
            file_mtime = datetime.fromtimestamp(backup_file.stat().st_mtime)
            if file_mtime < cutoff_date:
                backup_file.unlink()
                logger.info(f"ğŸ—‘ï¸ Deleted old driver backup: {backup_file}")
        
        # íŒ€ ë°±ì—… íŒŒì¼ ì •ë¦¬
        for backup_file in backup_dir.glob("team_2025_season_backup_*.json"):
            file_mtime = datetime.fromtimestamp(backup_file.stat().st_mtime)
            if file_mtime < cutoff_date:
                backup_file.unlink()
                logger.info(f"ğŸ—‘ï¸ Deleted old team backup: {backup_file}")
                
    except Exception as e:
        logger.warning(f"Failed to cleanup old backups: {e}")

def send_notification(success, message=""):
    """ì•Œë¦¼ ì „ì†¡ (ì„ íƒì‚¬í•­)"""
    try:
        # ìŠ¬ë™, ì´ë©”ì¼, ë˜ëŠ” ê¸°íƒ€ ì•Œë¦¼ ì„œë¹„ìŠ¤ í†µí•© ê°€ëŠ¥
        status = "âœ… SUCCESS" if success else "âŒ FAILED"
        notification_message = f"[OVERTAKE] Weekly F1 Statistics Scraping {status}\n{message}"
        
        # ì˜ˆì‹œ: ë¡œê·¸ íŒŒì¼ì— ì•Œë¦¼ ê¸°ë¡
        logger.info(f"ğŸ“¢ Notification: {notification_message}")
        
        # TODO: ì‹¤ì œ ì•Œë¦¼ ì„œë¹„ìŠ¤ ì—°ë™ (Slack, Email ë“±)
        
    except Exception as e:
        logger.warning(f"Failed to send notification: {e}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        # ì›”ìš”ì¼ì¸ì§€ í™•ì¸ (0=ì›”ìš”ì¼, 6=ì¼ìš”ì¼)
        today = datetime.now()
        if today.weekday() == 0:  # ì›”ìš”ì¼
            logger.info("ğŸ—“ï¸ Today is Monday - Running weekly scraping")
            success = run_weekly_scraper()
            
            if success:
                message = f"Driver and team statistics updated successfully on {today.strftime('%Y-%m-%d')}"
                send_notification(True, message)
                logger.info("=== Weekly F1 statistics scraping completed successfully ===")
            else:
                message = f"F1 statistics scraping failed on {today.strftime('%Y-%m-%d')}"
                send_notification(False, message)
                logger.error("=== Weekly F1 statistics scraping failed ===")
                sys.exit(1)
        else:
            logger.info(f"ğŸ—“ï¸ Today is {today.strftime('%A')} - Weekly scraping runs on Monday only")
            
    except Exception as e:
        logger.error(f"âŒ Main execution failed: {e}")
        send_notification(False, f"Main execution failed: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()